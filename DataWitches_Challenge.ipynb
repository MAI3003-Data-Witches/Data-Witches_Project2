{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc59ac1af6732554",
   "metadata": {},
   "source": [
    "# **Data Witches**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b45f2690fd28b7",
   "metadata": {},
   "source": [
    "| **Name**         | **Student ID** |\n",
    "|------------------|----------------|\n",
    "| Claessen, VVHJAE | i6339543       |\n",
    "| Ovsiannikova, AM | i6365923       |\n",
    "| Pubben, J        | i6276134       |\n",
    "| Roca Cugat, M    | i6351071       |\n",
    "| Záboj, J         | i6337952       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aece5caa34473",
   "metadata": {},
   "source": [
    "# **Logbook**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28fc7429c87cc80",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "Let's ensure we all use the same names for all components.\n",
    "\n",
    "| **Variable**                 | **Name**                                      |\n",
    "|------------------------------|-----------------------------------------------|\n",
    "| Raw ECG dataframe            | df                                            |\n",
    "| Label dataframe              | df_labels                                     |\n",
    "| HRV features (train)         | hrv_train                                     |\n",
    "| HRV features (test)          | hrv_test                                      |\n",
    "| HRV extraction type          | FULL (nk.hrv — time + freq + nonlinear + RSA) |\n",
    "| Clean HRV dataframe (train)  | hrv_train_clean                               |\n",
    "| Clean HRV dataframe (test)   | hrv_test_clean                                |\n",
    "| HRV + labels (train)         | hrv_train_with_labels                         |\n",
    "| Winsorized HRV column        | HRV_MedianNN_winsor                           |\n",
    "| Model feature matrix (train) | X_train                                       |\n",
    "| Model feature matrix (test)  | X_test                                        |\n",
    "| Model target vector (train)  | y_train                                       |\n",
    "| Model target vector (test)   | y_test                                        |\n",
    "\n",
    "\n",
    "| **Function**              | **Description**                                | **Arguments**                                |\n",
    "|---------------------------|------------------------------------------------|----------------------------------------------|\n",
    "| corr_plot_hrv()           | Correlation plot for HRV features              | df, cols=None                                |\n",
    "| distplots_hrv()           | Distribution plots (hist + KDE)                | df, cols=None                                |\n",
    "| boxplots_hrv()            | Boxplots for selected HRV variables            | df, cols                                     |\n",
    "| check_missing_hrv()       | Missingness summary                            | df                                           |\n",
    "| identify_outliers()       | IQR-based outlier detection                    | df, column_name, threshold=1.5               |\n",
    "| model_evaluation()        | Confusion matrix + classification report       | model                                        |\n",
    "| model_desc()              | Accuracy, CV, ROC-AUC, model performance       | model                                        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71e4ef40a858913",
   "metadata": {},
   "source": [
    "# Preface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25be65589590fcb3",
   "metadata": {},
   "source": [
    "## Packages imports"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "try:\n",
    "    print(\"Loading required packages...\")\n",
    "    import sys\n",
    "    import random\n",
    "    import os.path\n",
    "    import warnings\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import neurokit2 as nk\n",
    "    from scipy import stats\n",
    "    import scipy.signal as signal\n",
    "    from scipy.signal import welch\n",
    "    import matplotlib.pyplot as plt\n",
    "    from joblib.testing import xfail\n",
    "    import plotly.graph_objects as go\n",
    "    from colorama import Fore, Back, Style\n",
    "    from plotly.subplots import make_subplots\n",
    "\n",
    "    from sklearn import tree\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.compose import make_column_transformer\n",
    "    from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "    from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RepeatedStratifiedKFold\n",
    "    from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, \\\n",
    "        f1_score, precision_score, recall_score, roc_auc_score, roc_curve, RocCurveDisplay, precision_recall_curve\n",
    "    from sympy import false\n",
    "\n",
    "    print(\"Loading successful!\")\n",
    "except Exception:\n",
    "    print(\"Installing required packages...\")\n",
    "    !pip install -r https://raw.githubusercontent.com/MAI3003-Data-Witches/AtrialFibrillation-detection/refs/heads/challenge/requirements.txt\n",
    "\n",
    "    print(\"Loading required packages...\")\n",
    "    import sys\n",
    "    import random\n",
    "    import os.path\n",
    "    import warnings\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import neurokit2 as nk\n",
    "    from scipy import stats\n",
    "    import scipy.signal as signal\n",
    "    from scipy.signal import welch\n",
    "    import matplotlib.pyplot as plt\n",
    "    from joblib.testing import xfail\n",
    "    import plotly.graph_objects as go\n",
    "    from colorama import Fore, Back, Style\n",
    "    from plotly.subplots import make_subplots\n",
    "\n",
    "    from sklearn import tree\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.compose import make_column_transformer\n",
    "    from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "    from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RepeatedStratifiedKFold\n",
    "    from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, \\\n",
    "        f1_score, precision_score, recall_score, roc_auc_score, roc_curve, RocCurveDisplay, precision_recall_curve\n",
    "    from sympy import false\n",
    "\n",
    "    print(\"Loading successful!\")"
   ],
   "id": "935982e3a32ed56c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "59e2fb78a188e3b7",
   "metadata": {},
   "source": [
    "## Options settings"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(3003)\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "DATA_PRESENT = os.path.isfile(\"data/Physionet2017Training.tar.xz\")\n",
    "LoadPremadeDataset = True"
   ],
   "id": "819e915fcae8246a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset download",
   "id": "c86b5c3396c77ade"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dataset_location = 'data/Physionet2017TrainingData.csv'",
   "id": "733e8c8745ebdb32",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "322a29c57caf6a30",
   "metadata": {},
   "source": [
    "if not DATA_PRESENT:\n",
    "    !mkdir data\n",
    "    !wget https://github.com/MAI3003-Data-Witches/Data-Witches_Project2/raw/refs/heads/main/data/Physionet2017Training.tar.xz -O data/Physionet2017Training.tar.xz\n",
    "    !tar -xf data/Physionet2017Training.tar.xz -C data\n",
    "else:\n",
    "    print(f\"You already have the dataset downloaded at {dataset_location}, skipping\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8194ca8419d6a2c6",
   "metadata": {},
   "source": [
    "df = pd.read_csv(dataset_location, header=None, index_col=False) * 1000  # Load the dataset already in mV\n",
    "\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d791f19d174d1807",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "## Extract ECG signals and class labels"
   ]
  },
  {
   "cell_type": "code",
   "id": "df6051637427b19c",
   "metadata": {},
   "source": [
    "df_labels = pd.read_csv('data/Physionet2017TrainingLabels.csv', header=None, names=['label'])\n",
    "df_labels['classification'] = df_labels['label'].replace({\"N\": 0, \"A\": 1})\n",
    "df_labels['label'] = df_labels['label'].replace({\"N\": 'Normal Sinus Rhythm', \"A\": 'Atrial Fibrillation'})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ea89a4141e557191",
   "metadata": {},
   "source": [
    "df_labels"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7675a917e497d489",
   "metadata": {},
   "source": [
    "## Dataset splitting"
   ]
  },
  {
   "cell_type": "code",
   "id": "c5fced9de142ddf0",
   "metadata": {},
   "source": [
    "df_labeled = pd.merge(df_labels.drop(columns='label'), df, left_on='classification', right_index=True)\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    df.index,\n",
    "    test_size=0.2,\n",
    "    stratify=df_labels[\"label\"],\n",
    "    random_state=3003\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(train_idx))\n",
    "print(\"Test size:\", len(test_idx))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3828b0d61f36b49e",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "## Dataset characteristics"
   ]
  },
  {
   "cell_type": "code",
   "id": "84bd5e353e92a4f",
   "metadata": {},
   "source": [
    "num_ecgs = len(df)  # Number of ECGs\n",
    "\n",
    "num_samples = df.shape[1]  # Number of samples per ECG\n",
    "\n",
    "sampling_frequency = 300  #Hz\n",
    "duration = num_samples / sampling_frequency  # Duration of each ECG\n",
    "\n",
    "class_distribution = df_labels['label'].value_counts()  # Distribution over classes\n",
    "\n",
    "print(f\"Number of ECGs: {num_ecgs}\")\n",
    "print(f\"Number of samples per ECG: {num_samples}\")\n",
    "print(f\"Duration of each ECG: {duration} seconds\")\n",
    "print(f\"\\nClass Distribution:\\n{class_distribution}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "29c63dc163550429",
   "metadata": {},
   "source": [
    "# Indices per class (based on df_labels)\n",
    "sinus_indices = df_labels[df_labels[\"label\"] == \"Normal Sinus Rhythm\"].index.tolist()\n",
    "af_indices = df_labels[df_labels[\"label\"] == \"Atrial Fibrillation\"].index.tolist()\n",
    "\n",
    "example_sinus_idx = random.choice(sinus_indices)\n",
    "example_af_idx = random.choice(af_indices)\n",
    "\n",
    "ecg_sinus_raw = df.iloc[example_sinus_idx].astype(float).values\n",
    "ecg_af_raw = df.iloc[example_af_idx].astype(float).values\n",
    "\n",
    "time = np.arange(0, len(ecg_sinus_raw)) / sampling_frequency"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b6b534d7e483039f",
   "metadata": {},
   "source": [
    "# Summary statistics for each ECG\n",
    "summary_stats = df.describe().T\n",
    "summary_stats = pd.concat([summary_stats, df_labels], axis=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fbfb192ded15f5a0",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27b648ef4075e99",
   "metadata": {},
   "source": [
    "## ECG feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "id": "fd97ff94c0210770",
   "metadata": {},
   "source": [
    "# Select an ECG in Normal Sinus Rhythm and one in AF and process them\n",
    "selected_sinus_indices = random.sample(sinus_indices, 1)\n",
    "selected_af_indices = random.sample(af_indices, 1)\n",
    "\n",
    "ecg_NSR = df.iloc[selected_sinus_indices[0]].astype(float)\n",
    "signals_NSR, info_NSR = nk.ecg_process(ecg_NSR, sampling_rate=sampling_frequency)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 4]\n",
    "nk.ecg_plot(signals_NSR, info_NSR)\n",
    "\n",
    "ecg_AF = df.iloc[selected_af_indices[0]].astype(float)\n",
    "signals_AF, info_AF = nk.ecg_process(ecg_AF, sampling_rate=sampling_frequency)\n",
    "\n",
    "nk.ecg_plot(signals_AF, info_AF)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8f74f5d0762fab8b",
   "metadata": {},
   "source": [
    "#### R-peaks**"
   ]
  },
  {
   "cell_type": "code",
   "id": "b5cd75b1c1a167e8",
   "metadata": {},
   "source": [
    "# Find R-peaks\n",
    "peaks_NSR, info_NSR = nk.ecg_peaks(ecg_NSR, sampling_rate=sampling_frequency, correct_artifacts=True, show=True)\n",
    "peaks_AF, info_AF = nk.ecg_peaks(ecg_AF, sampling_rate=sampling_frequency, correct_artifacts=True, show=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "af2f35def467d115",
   "metadata": {},
   "source": [
    "#### Time-domain features"
   ]
  },
  {
   "cell_type": "code",
   "id": "abdd28449f7935bd",
   "metadata": {},
   "source": [
    "# Time domain features NSR\n",
    "hrv_time_NSR = nk.hrv_time(peaks_NSR, sampling_rate=sampling_frequency, show=True)\n",
    "hrv_time_NSR"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9fa3719508ed858d",
   "metadata": {},
   "source": [
    "# Time domain features AF\n",
    "hrv_time_AF = nk.hrv_time(peaks_AF, sampling_rate=sampling_frequency, show=True)\n",
    "hrv_time_AF"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "58c989c0300881b3",
   "metadata": {},
   "source": [
    "### FULL HRV feature extraction for all ECGs (TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "id": "66181ce776e08427",
   "metadata": {},
   "source": [
    "#Getting all the ECG readouts so we can extract P-wave information\n",
    "\n",
    "def get_ECG_readout():\n",
    "    test_run = 0\n",
    "    ecg_full = pd.DataFrame()  # Initialize an empty DataFrame\n",
    "\n",
    "    for i in tqdm(train_idx):\n",
    "\n",
    "        ecg = df.iloc[i].astype(float)\n",
    "        signals, info = nk.ecg_process(ecg, sampling_rate=sampling_frequency)\n",
    "\n",
    "        # Assign the current ecg_index to the signals DataFrame before concatenation\n",
    "        signals[\"ecg_index\"] = i\n",
    "\n",
    "        ecg_full = pd.concat([ecg_full, signals], ignore_index=True)\n",
    "\n",
    "        #test_run += 1\n",
    "\n",
    "        if test_run == 10:\n",
    "            break  # Stop after 10 iterations for the example\n",
    "\n",
    "    return ecg_full"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if LoadPremadeDataset == False:\n",
    "    ecg_full = get_ECG_readout()"
   ],
   "id": "70ea9b4db99ae781",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_ECG_metrics(ecg_full):\n",
    "    ecg_metrics_list = []\n",
    "\n",
    "    for i in tqdm(train_idx[:]):\n",
    "        mean_quality = ecg_full.loc[ecg_full.ecg_index == i]['ECG_Quality'].mean()\n",
    "        mean_pwave_amplitude = ecg_full.loc[(ecg_full.ecg_index == i) & (ecg_full['ECG_P_Peaks'] == 1)][\n",
    "            'ECG_Clean'].mean()  #You could consider taking sqrt, mean and then **2\n",
    "        #(more robust) to outliers\n",
    "        stdev_pwave = ecg_full.loc[(ecg_full.ecg_index == i) & (ecg_full['ECG_P_Peaks'] == 1)]['ECG_Quality'].std()\n",
    "        #Perhaps I could add something about irregularly irregular rhythm, but it's (really) difficult mathematically\n",
    "        ecg_metrics_list.append({\n",
    "            'Mean_Quality': mean_quality,\n",
    "            'Mean_PWave_Amplitude': mean_pwave_amplitude,\n",
    "            'STDEV_Pwave': stdev_pwave,\n",
    "            'ecg_index': i\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(ecg_metrics_list)"
   ],
   "id": "bc3570a7d46b4f4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if LoadPremadeDataset == False:\n",
    "    ecg_metrics = get_ECG_metrics(ecg_full)"
   ],
   "id": "34641567b50a2144",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if LoadPremadeDataset == False:\n",
    "    #FULL HRV feature extraction for all ECGs (TRAIN)\n",
    "\n",
    "    hrv_features_train = []\n",
    "\n",
    "    for i in tqdm(train_idx, desc=\"HRV (ALL FEATURES): TRAIN SET\"):\n",
    "        # Grab raw ECG\n",
    "        ecg = df.iloc[i].astype(float).values\n",
    "\n",
    "        try:\n",
    "            # 1. Clean ECG\n",
    "            ecg_clean = nk.ecg_clean(ecg, sampling_rate=sampling_frequency)\n",
    "\n",
    "            # 2. Detect R-peaks\n",
    "            peaks, _ = nk.ecg_peaks(\n",
    "                ecg_clean,\n",
    "                sampling_rate=sampling_frequency,\n",
    "                correct_artifacts=True\n",
    "            )\n",
    "\n",
    "            # 3. Compute FULL HRV feature set\n",
    "            hrv_full = nk.hrv(\n",
    "                peaks,\n",
    "                sampling_rate=sampling_frequency,\n",
    "                show=False\n",
    "            )\n",
    "\n",
    "            # Ensure row is a proper 1-row DataFrame and add ecg_index\n",
    "            hrv_full = hrv_full.copy()\n",
    "            hrv_full[\"ecg_index\"] = i\n",
    "\n",
    "            hrv_features_train.append(hrv_full)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing TRAIN ECG {i}: {e}\")\n",
    "\n",
    "            if hrv_features_train:\n",
    "                empty = pd.DataFrame(\n",
    "                    [np.nan] * hrv_features_train[0].shape[1],\n",
    "                    index=hrv_features_train[0].columns\n",
    "                ).T\n",
    "                empty[\"ecg_index\"] = i\n",
    "                hrv_features_train.append(empty)\n",
    "\n",
    "    # Combine to single DataFrame\n",
    "    hrv_train = pd.concat(hrv_features_train, ignore_index=True)\n",
    "\n",
    "    print(\"hrv_train shape:\", hrv_train.shape)\n",
    "    hrv_train.head()"
   ],
   "id": "ffe3c788bcbafcb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if LoadPremadeDataset == False:\n",
    "    # Merge our new dataframe with our extra variables\n",
    "    hrv_train = pd.merge(hrv_train, ecg_metrics, on='ecg_index', how='left')\n",
    "    hrv_train.head()"
   ],
   "id": "246f651e44e4a524",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if LoadPremadeDataset == False:\n",
    "    # Remove all columns from the dataframe that contain more than 50% NaN\n",
    "    threshold = 0.5\n",
    "    hrv_train_clean = hrv_train.dropna(thresh=len(hrv_train) * threshold, axis=1)\n",
    "\n",
    "    # Remove all rows that are all NaN\n",
    "    hrv_train_clean = hrv_train_clean.dropna(how='all')\n",
    "\n",
    "    hrv_train_clean.to_csv(\"data/hrv_train.csv\", index=False)\n",
    "    hrv_train_clean.head()"
   ],
   "id": "45d9970684e66736",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3d45a439ee1629c2",
   "metadata": {},
   "source": [
    "### FULL HRV feature extraction for all ECGs (TEST)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if LoadPremadeDataset == False:\n",
    "    hrv_features_test = []\n",
    "\n",
    "    for i in tqdm(test_idx, desc=\"HRV (ALL FEATURES): TEST SET\"):\n",
    "        ecg = df.iloc[i].astype(float).values\n",
    "\n",
    "        try:\n",
    "            # 1. Clean ECG\n",
    "            ecg_clean = nk.ecg_clean(ecg, sampling_rate=sampling_frequency)\n",
    "\n",
    "            # 2. Detect R-peaks\n",
    "            peaks, _ = nk.ecg_peaks(\n",
    "                ecg_clean,\n",
    "                sampling_rate=sampling_frequency,\n",
    "                correct_artifacts=True\n",
    "            )\n",
    "\n",
    "            # 3. Compute FULL HRV feature set\n",
    "            hrv_full = nk.hrv(\n",
    "                peaks,\n",
    "                sampling_rate=sampling_frequency,\n",
    "                show=False\n",
    "            )\n",
    "\n",
    "            # Same as TRAIN: keep as 1-row DataFrame, add index\n",
    "            hrv_full = hrv_full.copy()\n",
    "            hrv_full[\"ecg_index\"] = i\n",
    "\n",
    "            hrv_features_test.append(hrv_full)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing TEST ECG {i}: {e}\")\n",
    "\n",
    "            if hrv_features_test:\n",
    "                empty = pd.DataFrame(\n",
    "                    [np.nan] * hrv_features_test[0].shape[1],\n",
    "                    index=hrv_features_test[0].columns\n",
    "                ).T\n",
    "                empty[\"ecg_index\"] = i\n",
    "                hrv_features_test.append(empty)\n",
    "\n",
    "    hrv_test = pd.concat(hrv_features_test, ignore_index=True)\n",
    "\n",
    "    print(\"hrv_test shape:\", hrv_test.shape)\n",
    "    hrv_test.head()"
   ],
   "id": "a62cc3a091741aa9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if LoadPremadeDataset == False:\n",
    "    # Merge our new dataframe with our extra variables\n",
    "    hrv_test = pd.merge(hrv_test, ecg_metrics, on='ecg_index', how='left')\n",
    "    hrv_test.head()"
   ],
   "id": "9c6398a8f3c290bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if LoadPremadeDataset == False:\n",
    "    # Remove all columns from the dataframe that contain more than 50% NaN\n",
    "    threshold = 0.5\n",
    "    hrv_test_clean = hrv_test.dropna(thresh=len(hrv_test) * threshold, axis=1)\n",
    "\n",
    "    # Remove all rows that are all NaN\n",
    "    hrv_test_clean = hrv_test_clean.dropna(how='all')\n",
    "\n",
    "    hrv_test_clean.head()\n",
    "\n",
    "    hrv_test.to_csv(\"data/hrv_test.csv\", index=False)"
   ],
   "id": "b1f2417bae20eeac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# If you don't want to wait that long",
   "id": "665248a1390150b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if LoadPremadeDataset == True:\n",
    "    hrv_test_clean = pd.read_csv(\"data/hrv_test.csv\")\n",
    "    hrv_train_clean= pd.read_csv(\"data/hrv_train.csv\")"
   ],
   "id": "7e201ef017dbfd5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Feature exploration",
   "id": "75c6622e3b55e0cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Merge the HRV data with the rhythm labels\n",
    "hrv_train_with_labels = pd.merge(\n",
    "    hrv_train_clean, df_labels, left_on='ecg_index', right_index=True\n",
    ").reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "selectedMetric = 'HRV_MedianNN'\n",
    "rhythms = hrv_train_with_labels['label'].unique()\n",
    "for rhythm in rhythms:\n",
    "    subset = hrv_train_with_labels[hrv_train_with_labels['label'] == rhythm]\n",
    "    plt.hist(subset[selectedMetric], alpha=0.7, label=rhythm, bins='auto')\n",
    "\n",
    "plt.xlabel(selectedMetric)\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution by Rhythm')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "a98d942ff4c964dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "84011cdd339fb0a2",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd7156d74494298",
   "metadata": {},
   "source": [
    "## Missingness"
   ]
  },
  {
   "cell_type": "code",
   "id": "85661f71d7d18bdc",
   "metadata": {},
   "source": [
    "def check_missing_hrv(df):\n",
    "    \"\"\"\n",
    "    Summarize missingness across HRV features.\n",
    "    \"\"\"\n",
    "    missing = df.isna().sum()\n",
    "    out = pd.DataFrame({\n",
    "        \"feature\": df.columns,\n",
    "        \"missing_n\": missing,\n",
    "        \"missing_%\": (missing / len(df)) * 100\n",
    "    })\n",
    "    display(out.sort_values(\"missing_%\", ascending=False))\n",
    "    return out"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d610d38ba4561404",
   "metadata": {},
   "source": [
    "check_missing_hrv(hrv_train_clean)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a00714e3ee6f401e",
   "metadata": {},
   "source": [
    "## Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "id": "dc5d9abcf1bb4e03",
   "metadata": {},
   "source": [
    "# Function to identify outliers in the data\n",
    "def identify_outliers(df, column_name, threshold=1.5):\n",
    "    # Calculate Q1, Q3, and IQR\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define outlier bounds\n",
    "    lower_bound = Q1 - threshold * IQR\n",
    "    upper_bound = Q3 + threshold * IQR\n",
    "\n",
    "    # Identify outliers\n",
    "    row_indices = df[(df[column_name] < lower_bound) | (df[column_name] > upper_bound)].index.tolist()\n",
    "    outlier_values = df.loc[row_indices, column_name].tolist()\n",
    "\n",
    "    return row_indices, outlier_values, lower_bound, upper_bound"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7fa9774d200f7932",
   "metadata": {},
   "source": [
    "# Outlier detection ONLY ON TRAIN\n",
    "\n",
    "# Merge labels with TRAIN features (cleaned hrv_train)\n",
    "hrv_train_with_labels = pd.merge(\n",
    "    hrv_train_clean, df_labels, left_on=\"ecg_index\", right_index=True\n",
    ")\n",
    "\n",
    "# Outlier detection ONLY on TRAIN\n",
    "train_outlier_idx, outlier_values, iqr_lower, iqr_upper = identify_outliers(\n",
    "    hrv_train_with_labels,\n",
    "    \"HRV_MedianNN\",\n",
    "    threshold=1.5\n",
    ")\n",
    "\n",
    "# ecg_index as (int)\n",
    "hrv_train_with_labels[\"ecg_index\"] = hrv_train_with_labels[\"ecg_index\"].astype(int)\n",
    "\n",
    "print(\"Train outliers detected:\", len(train_outlier_idx))\n",
    "print(\"Row indices (in hrv_train_with_labels) with outliers:\", train_outlier_idx)\n",
    "print(\"Outlier HRV_MedianNN values:\", outlier_values)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c7026677b951d4dc",
   "metadata": {},
   "source": [
    "# Visualise one outlier ECG\n",
    "\n",
    "example_outlier_row = train_outlier_idx[0]\n",
    "\n",
    "# Single row\n",
    "row = hrv_train_with_labels.loc[example_outlier_row]\n",
    "\n",
    "# Extract ECG index value\n",
    "ecg_index_values = row.filter(like=\"ecg_index\").values\n",
    "\n",
    "# Use first value\n",
    "ecg_idx = int(ecg_index_values[0])\n",
    "\n",
    "# Extract raw ECG from df\n",
    "ecg_raw = df.iloc[ecg_idx].astype(float).values\n",
    "\n",
    "# Visualise R-Peaks\n",
    "peaks_outlier, info_outlier = nk.ecg_peaks(\n",
    "    ecg_raw,\n",
    "    sampling_rate=sampling_frequency,\n",
    "    correct_artifacts=True,\n",
    "    show=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6f7a3330073a16e7",
   "metadata": {},
   "source": [
    "hrv_train_with_labels.loc[example_outlier_row]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "76b35d498eed70a6",
   "metadata": {},
   "source": [
    "#### **Outliers TEST set** done the same way as for TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "id": "d355c44c827365f6",
   "metadata": {},
   "source": [
    "# Align TEST columns to TRAIN columns\n",
    "\n",
    "# Align TEST columns to TRAIN columns (no leakage, same feature space)\n",
    "train_cols = hrv_train_clean.columns  # already cleaned on TRAIN\n",
    "shared_cols = [c for c in train_cols if c in hrv_test_clean.columns]\n",
    "\n",
    "hrv_test_aligned = hrv_test_clean[shared_cols].copy()\n",
    "\n",
    "# Merge TEST HRV with labels\n",
    "hrv_test_with_labels = pd.merge(\n",
    "    hrv_test_aligned,\n",
    "    df_labels[[\"label\", \"classification\"]],\n",
    "    left_on=\"ecg_index\",\n",
    "    right_index=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "97a81e7e91f3cb56",
   "metadata": {},
   "source": [
    "# Same IQR bounds as on hrv_train\n",
    "\n",
    "Q1 = hrv_train_clean[\"HRV_MedianNN\"].quantile(0.25)\n",
    "Q3 = hrv_train_clean[\"HRV_MedianNN\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "hrv_test_clean = hrv_test_with_labels[\n",
    "    (hrv_test_with_labels[\"HRV_MedianNN\"] >= lower_bound) &\n",
    "    (hrv_test_with_labels[\"HRV_MedianNN\"] <= upper_bound)\n",
    "    ].copy()\n",
    "\n",
    "print(\"hrv_test shape:\", hrv_test_clean.shape)\n",
    "print(\"hrv_test_with_labels shape:\", hrv_test_with_labels.shape)\n",
    "print(\"hrv_test_clean shape:\", hrv_test_clean.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e8f18f565bb691b7",
   "metadata": {},
   "source": [
    "## Distribution TRAIN + TEST | Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "id": "95a28d78ac47363a",
   "metadata": {},
   "source": [
    "print(hrv_train_clean.columns[:5])\n",
    "print(hrv_test_clean.columns[:5])\n",
    "print(hrv_test_clean[[\"HRV_MedianNN\", \"classification\"]].head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3c25fde41c2e9aa6",
   "metadata": {},
   "source": [
    "for feat in [\"HRV_MedianNN\", \"HRV_SDNN\"]:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.kdeplot(\n",
    "        data=hrv_train_clean, x=feat, label=\"Train\", fill=True, common_norm=False\n",
    "    )\n",
    "    sns.kdeplot(\n",
    "        data=hrv_test_clean, x=feat, label=\"Test\", fill=True, common_norm=False, color=\"orange\"\n",
    "    )\n",
    "    plt.title(f\"{feat}: Train vs Test\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f5ba9ff7868a4a8b",
   "metadata": {},
   "source": [
    "### Outlier Handling TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2ff30ad886cc05",
   "metadata": {},
   "source": [
    "#### Winsorising outliers"
   ]
  },
  {
   "cell_type": "code",
   "id": "5e5ef13507fe5518",
   "metadata": {},
   "source": [
    "Q1 = hrv_train_with_labels[\"HRV_MedianNN\"].quantile(0.25)\n",
    "Q3 = hrv_train_with_labels[\"HRV_MedianNN\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_clip = Q1 - 1.5 * IQR\n",
    "upper_clip = Q3 + 1.5 * IQR\n",
    "\n",
    "hrv_train_winsor = hrv_train_with_labels.copy()\n",
    "hrv_train_winsor[\"HRV_MedianNN_winsor\"] = hrv_train_with_labels[\"HRV_MedianNN\"].clip(\n",
    "    lower=lower_clip, upper=upper_clip\n",
    ")\n",
    "\n",
    "print(\"Shape after winsorizing (same as original):\", hrv_train_winsor.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5784e0c94e4a6076",
   "metadata": {},
   "source": [
    "### Outlier Handling Comparison"
   ]
  },
  {
   "cell_type": "code",
   "id": "7e270ce4d4d3105d",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(hrv_train_with_labels[\"HRV_MedianNN\"], kde=True, color=\"red\", label=\"Original\")\n",
    "sns.histplot(hrv_train_winsor[\"HRV_MedianNN_winsor\"], kde=True, color=\"green\", label=\"Winsorized\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Outlier Handling Comparison\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8811d9407209d33f",
   "metadata": {},
   "source": [
    "# Final Preprocessing: Building ML Matrices (X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "id": "808717ddc32befd1",
   "metadata": {},
   "source": [
    "# Select HRV feature columns only\n",
    "feature_cols = [col for col in hrv_train_with_labels.columns if col.startswith(\"HRV_\")]\n",
    "\n",
    "# TRAIN data\n",
    "x_train = hrv_train_with_labels[feature_cols].copy()\n",
    "y_train = hrv_train_with_labels[\"classification\"].copy()\n",
    "\n",
    "# TEST data\n",
    "x_test = hrv_test_clean[feature_cols].copy()\n",
    "y_test = hrv_test_clean[\"classification\"].copy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4205f6e90e740053",
   "metadata": {},
   "source": [
    "# Replace +/- inf with NaN in both TRAIN and TEST\n",
    "for df_ in (x_train, x_test):\n",
    "    df_.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Drop columns that are all-NaN (if any)\n",
    "all_nan_cols = x_train.columns[x_train.isna().all()]\n",
    "if len(all_nan_cols) > 0:\n",
    "    print(\"Dropping all-NaN columns before imputation:\", list(all_nan_cols))\n",
    "    x_train.drop(columns=all_nan_cols, inplace=True)\n",
    "    x_test.drop(columns=all_nan_cols, inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f416990de42cd4a3",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "code",
   "id": "331970276ce7a777",
   "metadata": {},
   "source": [
    "# Median imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "# X_train: fit_transform\n",
    "X_train_imputed = imputer.fit_transform(x_train)\n",
    "\n",
    "# X_test: only transform (so test set remains untouched)\n",
    "X_test_imputed = imputer.transform(x_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "15abcdeb289f5573",
   "metadata": {},
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "id": "c5d065ed84b20c34",
   "metadata": {},
   "source": [
    "#Temporarily convert to DataFrame to calculate Skewness easily\n",
    "temp_df = pd.DataFrame(X_train_imputed, columns=feature_cols)\n",
    "skewness = temp_df.skew().sort_values(ascending=False)\n",
    "\n",
    "#Identify skewed columns (Threshold > 1.0)\n",
    "skewed_cols = skewness[abs(skewness) > 1.0].index.tolist()\n",
    "\n",
    "#Apply Log Transform directly to the NumPy arrays\n",
    "for col_name in skewed_cols:\n",
    "    # Find the column index (integer position)\n",
    "    col_idx = feature_cols.index(col_name)\n",
    "\n",
    "    # Check for negative values (Log crashes on negatives)\n",
    "    # We find the global minimum for this column across Train and Test\n",
    "    min_val = min(X_train_imputed[:, col_idx].min(), X_test_imputed[:, col_idx].min())\n",
    "\n",
    "    shift = 0\n",
    "    if min_val < 0:\n",
    "        # If negatives exist, calculate a shift to make the minimum 0\n",
    "        shift = abs(min_val)\n",
    "\n",
    "    # Apply transformation in-place: Log(x + shift + 1)\n",
    "    X_train_imputed[:, col_idx] = np.log1p(X_train_imputed[:, col_idx] + shift)\n",
    "    X_test_imputed[:, col_idx] = np.log1p(X_test_imputed[:, col_idx] + shift)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "51d3ff7d06fd93cc",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "id": "b86af43c55a5ba1d",
   "metadata": {},
   "source": [
    "scaler = RobustScaler()\n",
    "\n",
    "# X_train: fit_transform\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "\n",
    "# X_test: only transform (so test set remains untouched)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Convert back to df with column names\n",
    "x_train = pd.DataFrame(X_train_scaled, columns=feature_cols)\n",
    "x_test = pd.DataFrame(X_test_scaled, columns=feature_cols)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ec382f92da049c00",
   "metadata": {},
   "source": [
    "### **Sanity checks**"
   ]
  },
  {
   "cell_type": "code",
   "id": "26f29c228cb64bf1",
   "metadata": {},
   "source": [
    "# Median X_train\n",
    "print(\"Median of scaled features (should be ~0):\")\n",
    "print(x_train.median().round(3))\n",
    "\n",
    "# IQR X_train\n",
    "print(\"\\nIQR of scaled features (should be ~1):\")\n",
    "print((x_train.quantile(0.75) - x_train.quantile(0.25)).round(3))\n",
    "\n",
    "#Checking skewness of the datasets\n",
    "skewness_train = x_train.skew().sort_values(ascending=False)\n",
    "skewness_test = x_train.skew().sort_values(ascending=False)\n",
    "# Filter for highly skewed columns (absolute skew > 1.0)\n",
    "high_skew_cols_train = skewness_train[abs(skewness_train) > 1.0]\n",
    "high_skew_cols_test = skewness_test[abs(skewness_test) > 1.0]\n",
    "\n",
    "print(len(high_skew_cols_train))\n",
    "print(len(high_skew_cols_test))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2a36ba7605b95a6a",
   "metadata": {},
   "source": [
    "# Final ML datasets (X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "id": "92cc335720ca9288",
   "metadata": {},
   "source": [
    "print(\"Train size:\", len(train_idx))\n",
    "print(\"Test size:\", len(test_idx))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ec10523a1e004990",
   "metadata": {},
   "source": [
    "if True:\n",
    "    # Feature matrices (winsorised > imputation > scaling)\n",
    "    x_train = X_train_scaled\n",
    "    x_test = X_test_scaled\n",
    "\n",
    "    # Target vectors (created earlier from HRV + labels AF(0/1))\n",
    "    y_train = hrv_train_with_labels[\"classification\"].copy()\n",
    "    y_test = hrv_test_clean[\"classification\"].copy()\n",
    "\n",
    "    print(\"Final X_train shape:\", x_train.shape)\n",
    "    print(\"Final X_test shape:\", x_test.shape)\n",
    "    print(\"Final y_train shape:\", y_train.shape)\n",
    "    print(\"Final y_test shape:\", y_test.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "24142419a84363d0",
   "metadata": {},
   "source": [
    "# Machine Learning Training Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d1464a95c41b61",
   "metadata": {},
   "source": [
    "## Safety check"
   ]
  },
  {
   "cell_type": "code",
   "id": "fd31ca358371c93e",
   "metadata": {},
   "source": [
    "assert len(x_train) == len(y_train), \"Misaligned TRAIN matrix and labels!\"\n",
    "assert len(x_test) == len(y_test), \"Misaligned TEST matrix and labels!\"\n",
    "\n",
    "assert not np.isnan(x_train).any(), \"NaNs detected in X_train!\"\n",
    "assert not np.isnan(x_test).any(), \"NaNs detected in X_test!\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "12e32109e5ee457",
   "metadata": {},
   "source": [
    "## Comparison framework"
   ]
  },
  {
   "cell_type": "code",
   "id": "37efe7aec3749c6",
   "metadata": {},
   "source": [
    "resultsTable = pd.DataFrame(columns=['Model', 'Accuracy', 'F1 Score', 'Precision', 'Recall', 'ROC', 'ROC_AUC', 'cm'])\n",
    "\n",
    "def modelResults(model, accuracy, f1, precision, recall, roc_auc, roc_cur, cm):\n",
    "    print(\n",
    "        f\"Model {model} evaluated. \\nAccuracy: {accuracy} \\nF1 Score: {f1} \\nPrecision: {precision} \\nRecall: {recall} \\nROC AUC: {roc_auc}\")\n",
    "    resultsTable.loc[len(resultsTable)] = [model, accuracy, f1, precision, recall, roc_cur, roc_auc, cm]\n",
    "    resultsTable.to_csv(\"data/trainingResults.csv\", index=False, mode=\"a\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hyperParameterResultsTable = pd.DataFrame(columns=['Model', 'Accuracy', 'F1 Score', 'Precision', 'Recall', 'ROC', 'ROC_AUC', 'cm'])\n",
    "\n",
    "def hyperParameterResults(model, accuracy, f1, precision, recall, roc_auc, roc_cur, cm):\n",
    "    print(\n",
    "        f\"Model {model} evaluated. \\nAccuracy: {accuracy} \\nF1 Score: {f1} \\nPrecision: {precision} \\nRecall: {recall} \\nROC AUC: {roc_auc}\")\n",
    "    hyperParameterResultsTable.loc[len(resultsTable)] = [model, accuracy, f1, precision, recall, roc_cur, roc_auc, cm]\n",
    "    hyperParameterResultsTable.to_csv(\"data/hyperParameterResults.csv\", index=False, mode=\"a\")\n"
   ],
   "id": "624ad9d92ed62fa8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4886d8bf749e585f",
   "metadata": {},
   "source": [
    "print(\n",
    "    f\"X train length: {len(x_train)}\\n X test length: {len(x_test)} \\n Y train length: {len(y_train)}\\n Y test length: {len(y_test)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "50d9a88ad21d69c1",
   "metadata": {},
   "source": [
    "# Machine Learning Training"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "#Going back to basics, the currently used x_train and x_test gave ValueErrors as negative values for Log\n",
    "\n",
    "raw_cols = [c for c in hrv_train_with_labels.columns if c.startswith(\"HRV_\")]\n",
    "raw_train = hrv_train_with_labels[raw_cols].copy()\n",
    "raw_test = hrv_test_clean[raw_cols].copy()\n",
    "\n",
    "raw_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "raw_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "imputer_eng = SimpleImputer(strategy=\"median\")\n",
    "raw_train_imp = pd.DataFrame(imputer_eng.fit_transform(raw_train), columns=raw_cols)\n",
    "raw_test_imp = pd.DataFrame(imputer_eng.transform(raw_test), columns=raw_cols)\n",
    "\n",
    "skewness = raw_train_imp.skew().sort_values(ascending=False)\n",
    "skewed_cols = skewness[abs(skewness) > 1.0].index.tolist()\n",
    "\n",
    "new_features_train = pd.DataFrame(index=raw_train_imp.index)\n",
    "new_features_test = pd.DataFrame(index=raw_test_imp.index)\n",
    "\n",
    "#1. Log Transforms\n",
    "for col in skewed_cols:\n",
    "    # +1e-6 avoids log(0)\n",
    "    new_features_train[f'Log_{col}'] = np.log(raw_train_imp[col] + 1e-6)\n",
    "    new_features_test[f'Log_{col}'] = np.log(raw_test_imp[col] + 1e-6)\n",
    "\n",
    "#2. 2. Coefficient of Variation (CV) computation:\n",
    "if 'HRV_SDNN' in raw_train_imp.columns and 'HRV_MeanNN' in raw_train_imp.columns:\n",
    "    new_features_train['CV_SDNN'] = raw_train_imp['HRV_SDNN'] / (raw_train_imp['HRV_MeanNN'] + 1e-6)\n",
    "    new_features_test['CV_SDNN'] = raw_test_imp['HRV_SDNN'] / (raw_test_imp['HRV_MeanNN'] + 1e-6)\n",
    "\n",
    "# 3. Chaos Index (Amplifies the \"irregularly irregular\" signal specific to AF.):\n",
    "entropy_col = 'HRV_ApEn' if 'HRV_ApEn' in raw_train_imp.columns else 'HRV_SampEn'\n",
    "if 'HRV_RMSSD' in raw_train_imp.columns and entropy_col in raw_train_imp.columns:\n",
    "    new_features_train['Chaos_Index'] = raw_train_imp['HRV_RMSSD'] * raw_train_imp[entropy_col]\n",
    "    new_features_test['Chaos_Index'] = raw_test_imp['HRV_RMSSD'] * raw_test_imp[entropy_col]\n",
    "\n",
    "new_features_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "new_features_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "imputer_new = SimpleImputer(strategy=\"median\")\n",
    "new_train_clean = pd.DataFrame(imputer_new.fit_transform(new_features_train), columns=new_features_train.columns)\n",
    "new_test_clean = pd.DataFrame(imputer_new.transform(new_features_test), columns=new_features_test.columns)\n",
    "\n",
    "scaler_eng = RobustScaler()\n",
    "new_train_scaled = pd.DataFrame(scaler_eng.fit_transform(new_train_clean), columns=new_features_train.columns)\n",
    "new_test_scaled = pd.DataFrame(scaler_eng.transform(new_test_clean), columns=new_features_test.columns)\n",
    "\n",
    "if not isinstance(x_train, pd.DataFrame):\n",
    "    x_train = pd.DataFrame(x_train, columns=feature_cols)\n",
    "if not isinstance(x_test, pd.DataFrame):\n",
    "    x_test = pd.DataFrame(x_test, columns=feature_cols)\n",
    "\n",
    "x_train_added = pd.concat([x_train, new_train_scaled], axis=1)\n",
    "x_test_added = pd.concat([x_test, new_test_scaled], axis=1)"
   ],
   "id": "466a673194d59ec6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "97a1a9262acb8046",
   "metadata": {},
   "source": [
    "## Soft voting classifier"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Hyperparameter sweep",
   "id": "efbfe26e8dc93982"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, roc_curve, \\\n",
    "    confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_tr = x_train_added if 'x_train_added' in globals() else x_train\n",
    "X_te = x_test_added if 'x_test_added' in globals() else x_test\n",
    "\n",
    "if isinstance(X_tr, np.ndarray):\n",
    "    X_tr_use = X_tr\n",
    "    X_te_use = X_te\n",
    "else:\n",
    "    X_tr_use = X_tr.values\n",
    "    X_te_use = X_te.values\n",
    "\n",
    "y_tr_use = y_train.values if isinstance(y_train, pd.Series) else y_train\n",
    "y_te_use = y_test.values if isinstance(y_test, pd.Series) else y_test\n",
    "\n",
    "solvers_grid = ['lbfgs', 'liblinear', 'saga']\n",
    "penalties_by_solver = {\n",
    "    'lbfgs': ['l2', None],\n",
    "    'liblinear': ['l1', 'l2'],\n",
    "    'saga': ['l1', 'l2', 'elasticnet']\n",
    "}\n",
    "Cs = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "class_weights = [None, 'balanced']\n",
    "max_iter = 2000\n",
    "l1_ratio_values = [0.0, 0.25, 0.5, 0.75]\n",
    "\n",
    "for solver in solvers_grid:\n",
    "    for penalty in penalties_by_solver[solver]:\n",
    "        for C in Cs:\n",
    "            for cw in class_weights:\n",
    "                if penalty == 'elasticnet' and solver == 'saga':\n",
    "                    for l1r in l1_ratio_values:\n",
    "                        try:\n",
    "                            model = LogisticRegression(\n",
    "                                solver=solver,\n",
    "                                penalty=penalty,\n",
    "                                C=C,\n",
    "                                l1_ratio=l1r,\n",
    "                                class_weight=cw,\n",
    "                                max_iter=max_iter,\n",
    "                                n_jobs=-1 if solver in ['lbfgs', 'saga'] else None,\n",
    "                                random_state=3003\n",
    "                            )\n",
    "                            model.fit(X_tr_use, y_tr_use)\n",
    "                            y_pred = model.predict(X_te_use)\n",
    "                            y_proba = model.predict_proba(X_te_use)[:, 1]\n",
    "                            acc = accuracy_score(y_te_use, y_pred)\n",
    "                            f1 = f1_score(y_te_use, y_pred)\n",
    "                            prec = precision_score(y_te_use, y_pred)\n",
    "                            rec = recall_score(y_te_use, y_pred)\n",
    "                            auc = roc_auc_score(y_te_use, y_proba)\n",
    "                            roc_cur = roc_curve(y_te_use, y_proba)\n",
    "                            cm = confusion_matrix(y_true=y_te_use, y_pred=y_pred, normalize='true')\n",
    "                            name = f\"LR(solver={solver},penalty={penalty},C={C},class_weight={cw},l1_ratio={l1r})\"\n",
    "                            hyperParameterResults(name, acc, f1, prec, rec, auc, roc_cur, cm)\n",
    "                        except Exception as e:\n",
    "                            continue\n",
    "                else:\n",
    "                    try:\n",
    "                        kwargs = dict(\n",
    "                            solver=solver,\n",
    "                            penalty=penalty if penalty is not None else 'l2',\n",
    "                            C=C,\n",
    "                            class_weight=cw,\n",
    "                            max_iter=max_iter,\n",
    "                            n_jobs=-1 if solver in ['lbfgs', 'saga'] else None,\n",
    "                            random_state=3003\n",
    "                        )\n",
    "                        if penalty != 'elasticnet' and 'l1_ratio' in kwargs:\n",
    "                            kwargs.pop('l1_ratio', None)\n",
    "                        if solver == 'liblinear' and kwargs.get('n_jobs') is not None:\n",
    "                            kwargs.pop('n_jobs', None)\n",
    "\n",
    "                        model = LogisticRegression(**kwargs)\n",
    "                        model.fit(X_tr_use, y_tr_use)\n",
    "                        y_pred = model.predict(X_te_use)\n",
    "                        y_proba = model.predict_proba(X_te_use)[:, 1]\n",
    "                        acc = accuracy_score(y_te_use, y_pred)\n",
    "                        f1 = f1_score(y_te_use, y_pred)\n",
    "                        prec = precision_score(y_te_use, y_pred)\n",
    "                        rec = recall_score(y_te_use, y_pred)\n",
    "                        auc = roc_auc_score(y_te_use, y_proba)\n",
    "                        roc_cur = roc_curve(y_te_use, y_proba)\n",
    "                        cm = confusion_matrix(y_true=y_te_use, y_pred=y_pred, normalize='true')\n",
    "                        name = f\"LR(solver={solver},penalty={penalty},C={C},class_weight={cw})\"\n",
    "                        hyperParameterResults(name, acc, f1, prec, rec, auc, roc_cur, cm)\n",
    "                    except Exception as e:\n",
    "                        continue\n"
   ],
   "id": "5749a9f0d5b406b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, roc_curve, \\\n",
    "    confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_tr = x_train_added if 'x_train_added' in globals() else x_train\n",
    "X_te = x_test_added if 'x_test_added' in globals() else x_test\n",
    "\n",
    "if isinstance(X_tr, np.ndarray):\n",
    "    X_tr_use = X_tr\n",
    "    X_te_use = X_te\n",
    "else:\n",
    "    X_tr_use = X_tr.values\n",
    "    X_te_use = X_te.values\n",
    "\n",
    "y_tr_use = y_train.values if isinstance(y_train, pd.Series) else y_train\n",
    "y_te_use = y_test.values if isinstance(y_test, pd.Series) else y_test\n",
    "\n",
    "n_estimators_grid = [50, 100, 200, 300, 500]\n",
    "max_depth_grid = [None, 5, 10, 20, 30]\n",
    "min_samples_split_grid = [2, 5, 10]\n",
    "min_samples_leaf_grid = [1, 2, 4]\n",
    "max_features_grid = ['sqrt', 'log2', None]\n",
    "bootstrap_grid = [True, False]\n",
    "class_weight_grid = [None, 'balanced', 'balanced_subsample']\n",
    "criterion_grid = ['gini', 'entropy', 'log_loss']\n",
    "oob_score_grid = [False, True]\n",
    "\n",
    "for n_est in n_estimators_grid:\n",
    "    for crit in criterion_grid:\n",
    "        for md in max_depth_grid:\n",
    "            for mss in min_samples_split_grid:\n",
    "                for msl in min_samples_leaf_grid:\n",
    "                    for mf in max_features_grid:\n",
    "                        for bs in bootstrap_grid:\n",
    "                            if (not bs):\n",
    "                                oob = False\n",
    "                                oob_list = [False]\n",
    "                            else:\n",
    "                                oob_list = oob_score_grid\n",
    "                            for oob in oob_list:\n",
    "                                for cw in class_weight_grid:\n",
    "                                    try:\n",
    "                                        model = RandomForestClassifier(\n",
    "                                            n_estimators=n_est,\n",
    "                                            criterion=crit,\n",
    "                                            max_depth=md,\n",
    "                                            min_samples_split=mss,\n",
    "                                            min_samples_leaf=msl,\n",
    "                                            max_features=mf,\n",
    "                                            bootstrap=bs,\n",
    "                                            oob_score=oob,\n",
    "                                            class_weight=cw,\n",
    "                                            n_jobs=-1,\n",
    "                                            random_state=3003\n",
    "                                        )\n",
    "                                        model.fit(X_tr_use, y_tr_use)\n",
    "                                        y_pred = model.predict(X_te_use)\n",
    "                                        y_proba = model.predict_proba(X_te_use)[:, 1]\n",
    "                                        acc = accuracy_score(y_te_use, y_pred)\n",
    "                                        f1 = f1_score(y_te_use, y_pred)\n",
    "                                        prec = precision_score(y_te_use, y_pred)\n",
    "                                        rec = recall_score(y_te_use, y_pred)\n",
    "                                        auc = roc_auc_score(y_te_use, y_proba)\n",
    "                                        roc_cur = roc_curve(y_te_use, y_proba)\n",
    "                                        cm = confusion_matrix(y_true=y_te_use, y_pred=y_pred, normalize='true')\n",
    "                                        name = f\"RF(n_estimators={n_est},criterion={crit},max_depth={md},min_samples_split={mss},min_samples_leaf={msl},max_features={mf},bootstrap={bs},oob_score={oob},class_weight={cw})\"\n",
    "                                        hyperParameterResults(name, acc, f1, prec, rec, auc, roc_cur, cm)\n",
    "                                    except Exception:\n",
    "                                        continue\n"
   ],
   "id": "eb787224f7bf3a54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=5,min_samples_leaf=4,max_features=None,bootstrap=False,oob_score=False,class_weight=None) evaluated. \n",
      "Accuracy: 0.9460067491563554 \n",
      "F1 Score: 0.75 \n",
      "Precision: 0.8089887640449438 \n",
      "Recall: 0.6990291262135923 \n",
      "ROC AUC: 0.8691605523851873\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=5,min_samples_leaf=4,max_features=None,bootstrap=False,oob_score=False,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9448818897637795 \n",
      "F1 Score: 0.776255707762557 \n",
      "Precision: 0.7327586206896551 \n",
      "Recall: 0.8252427184466019 \n",
      "ROC AUC: 0.904197238074063\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=5,min_samples_leaf=4,max_features=None,bootstrap=False,oob_score=False,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9448818897637795 \n",
      "F1 Score: 0.776255707762557 \n",
      "Precision: 0.7327586206896551 \n",
      "Recall: 0.8252427184466019 \n",
      "ROC AUC: 0.904197238074063\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=sqrt,bootstrap=True,oob_score=False,class_weight=None) evaluated. \n",
      "Accuracy: 0.9617547806524185 \n",
      "F1 Score: 0.8172043010752689 \n",
      "Precision: 0.9156626506024096 \n",
      "Recall: 0.7378640776699029 \n",
      "ROC AUC: 0.9786926554509746\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=sqrt,bootstrap=True,oob_score=False,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9640044994375703 \n",
      "F1 Score: 0.8315789473684211 \n",
      "Precision: 0.9080459770114943 \n",
      "Recall: 0.7669902912621359 \n",
      "ROC AUC: 0.9790508658810742\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=sqrt,bootstrap=True,oob_score=False,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9640044994375703 \n",
      "F1 Score: 0.8315789473684211 \n",
      "Precision: 0.9080459770114943 \n",
      "Recall: 0.7669902912621359 \n",
      "ROC AUC: 0.983423503545048\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=sqrt,bootstrap=True,oob_score=True,class_weight=None) evaluated. \n",
      "Accuracy: 0.9617547806524185 \n",
      "F1 Score: 0.8172043010752689 \n",
      "Precision: 0.9156626506024096 \n",
      "Recall: 0.7378640776699029 \n",
      "ROC AUC: 0.9786926554509746\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=sqrt,bootstrap=True,oob_score=True,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9640044994375703 \n",
      "F1 Score: 0.8315789473684211 \n",
      "Precision: 0.9080459770114943 \n",
      "Recall: 0.7669902912621359 \n",
      "ROC AUC: 0.9790508658810742\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=sqrt,bootstrap=True,oob_score=True,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9640044994375703 \n",
      "F1 Score: 0.8315789473684211 \n",
      "Precision: 0.9080459770114943 \n",
      "Recall: 0.7669902912621359 \n",
      "ROC AUC: 0.983423503545048\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=sqrt,bootstrap=False,oob_score=False,class_weight=None) evaluated. \n",
      "Accuracy: 0.9651293588301463 \n",
      "F1 Score: 0.8359788359788359 \n",
      "Precision: 0.9186046511627907 \n",
      "Recall: 0.7669902912621359 \n",
      "ROC AUC: 0.9846648879666\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=sqrt,bootstrap=False,oob_score=False,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9662542182227222 \n",
      "F1 Score: 0.845360824742268 \n",
      "Precision: 0.9010989010989011 \n",
      "Recall: 0.7961165048543689 \n",
      "ROC AUC: 0.9804775315595741\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=sqrt,bootstrap=False,oob_score=False,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9662542182227222 \n",
      "F1 Score: 0.845360824742268 \n",
      "Precision: 0.9010989010989011 \n",
      "Recall: 0.7961165048543689 \n",
      "ROC AUC: 0.9804775315595741\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=log2,bootstrap=True,oob_score=False,class_weight=None) evaluated. \n",
      "Accuracy: 0.9606299212598425 \n",
      "F1 Score: 0.8128342245989305 \n",
      "Precision: 0.9047619047619048 \n",
      "Recall: 0.7378640776699029 \n",
      "ROC AUC: 0.9812680649225524\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=log2,bootstrap=True,oob_score=False,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9640044994375703 \n",
      "F1 Score: 0.8350515463917526 \n",
      "Precision: 0.8901098901098901 \n",
      "Recall: 0.7864077669902912 \n",
      "ROC AUC: 0.9823118160033598\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=log2,bootstrap=True,oob_score=False,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9628796400449944 \n",
      "F1 Score: 0.8290155440414507 \n",
      "Precision: 0.8888888888888888 \n",
      "Recall: 0.7766990291262136 \n",
      "ROC AUC: 0.9823118160033597\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=log2,bootstrap=True,oob_score=True,class_weight=None) evaluated. \n",
      "Accuracy: 0.9606299212598425 \n",
      "F1 Score: 0.8128342245989305 \n",
      "Precision: 0.9047619047619048 \n",
      "Recall: 0.7378640776699029 \n",
      "ROC AUC: 0.9812680649225524\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=log2,bootstrap=True,oob_score=True,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9640044994375703 \n",
      "F1 Score: 0.8350515463917526 \n",
      "Precision: 0.8901098901098901 \n",
      "Recall: 0.7864077669902912 \n",
      "ROC AUC: 0.9823118160033598\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=log2,bootstrap=True,oob_score=True,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9628796400449944 \n",
      "F1 Score: 0.8290155440414507 \n",
      "Precision: 0.8888888888888888 \n",
      "Recall: 0.7766990291262136 \n",
      "ROC AUC: 0.9823118160033597\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=log2,bootstrap=False,oob_score=False,class_weight=None) evaluated. \n",
      "Accuracy: 0.9606299212598425 \n",
      "F1 Score: 0.8148148148148148 \n",
      "Precision: 0.8953488372093024 \n",
      "Recall: 0.7475728155339806 \n",
      "ROC AUC: 0.9819412534894636\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=log2,bootstrap=False,oob_score=False,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9640044994375703 \n",
      "F1 Score: 0.8350515463917526 \n",
      "Precision: 0.8901098901098901 \n",
      "Recall: 0.7864077669902912 \n",
      "ROC AUC: 0.9826947306010524\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=log2,bootstrap=False,oob_score=False,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9640044994375703 \n",
      "F1 Score: 0.8350515463917526 \n",
      "Precision: 0.8901098901098901 \n",
      "Recall: 0.7864077669902912 \n",
      "ROC AUC: 0.9826947306010524\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=None,bootstrap=True,oob_score=False,class_weight=None) evaluated. \n",
      "Accuracy: 0.9628796400449944 \n",
      "F1 Score: 0.8253968253968254 \n",
      "Precision: 0.9069767441860465 \n",
      "Recall: 0.7572815533980582 \n",
      "ROC AUC: 0.983652017095284\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=None,bootstrap=True,oob_score=False,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9628796400449944 \n",
      "F1 Score: 0.8272251308900523 \n",
      "Precision: 0.8977272727272727 \n",
      "Recall: 0.7669902912621359 \n",
      "ROC AUC: 0.9815274586822798\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=None,bootstrap=True,oob_score=False,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9606299212598425 \n",
      "F1 Score: 0.8148148148148148 \n",
      "Precision: 0.8953488372093024 \n",
      "Recall: 0.7475728155339806 \n",
      "ROC AUC: 0.9786000148225005\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=None,bootstrap=True,oob_score=True,class_weight=None) evaluated. \n",
      "Accuracy: 0.9628796400449944 \n",
      "F1 Score: 0.8253968253968254 \n",
      "Precision: 0.9069767441860465 \n",
      "Recall: 0.7572815533980582 \n",
      "ROC AUC: 0.983652017095284\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=None,bootstrap=True,oob_score=True,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9628796400449944 \n",
      "F1 Score: 0.8272251308900523 \n",
      "Precision: 0.8977272727272727 \n",
      "Recall: 0.7669902912621359 \n",
      "ROC AUC: 0.9815274586822798\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=None,bootstrap=True,oob_score=True,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9606299212598425 \n",
      "F1 Score: 0.8148148148148148 \n",
      "Precision: 0.8953488372093024 \n",
      "Recall: 0.7475728155339806 \n",
      "ROC AUC: 0.9786000148225005\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=None,bootstrap=False,oob_score=False,class_weight=None) evaluated. \n",
      "Accuracy: 0.9415073115860517 \n",
      "F1 Score: 0.7319587628865979 \n",
      "Precision: 0.7802197802197802 \n",
      "Recall: 0.6893203883495146 \n",
      "ROC AUC: 0.843869660811779\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=None,bootstrap=False,oob_score=False,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9448818897637795 \n",
      "F1 Score: 0.7699530516431925 \n",
      "Precision: 0.7454545454545455 \n",
      "Recall: 0.7961165048543689 \n",
      "ROC AUC: 0.9041107734874874\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=1,max_features=None,bootstrap=False,oob_score=False,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9448818897637795 \n",
      "F1 Score: 0.7699530516431925 \n",
      "Precision: 0.7454545454545455 \n",
      "Recall: 0.7961165048543689 \n",
      "ROC AUC: 0.9041107734874874\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=sqrt,bootstrap=True,oob_score=False,class_weight=None) evaluated. \n",
      "Accuracy: 0.9583802024746907 \n",
      "F1 Score: 0.8 \n",
      "Precision: 0.9024390243902439 \n",
      "Recall: 0.7184466019417476 \n",
      "ROC AUC: 0.9827317868524421\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=sqrt,bootstrap=True,oob_score=False,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9651293588301463 \n",
      "F1 Score: 0.837696335078534 \n",
      "Precision: 0.9090909090909091 \n",
      "Recall: 0.7766990291262136 \n",
      "ROC AUC: 0.9820647743274291\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=sqrt,bootstrap=True,oob_score=False,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9628796400449944 \n",
      "F1 Score: 0.8272251308900523 \n",
      "Precision: 0.8977272727272727 \n",
      "Recall: 0.7669902912621359 \n",
      "ROC AUC: 0.9834358556288446\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=sqrt,bootstrap=True,oob_score=True,class_weight=None) evaluated. \n",
      "Accuracy: 0.9583802024746907 \n",
      "F1 Score: 0.8 \n",
      "Precision: 0.9024390243902439 \n",
      "Recall: 0.7184466019417476 \n",
      "ROC AUC: 0.9827317868524421\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=sqrt,bootstrap=True,oob_score=True,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9651293588301463 \n",
      "F1 Score: 0.837696335078534 \n",
      "Precision: 0.9090909090909091 \n",
      "Recall: 0.7766990291262136 \n",
      "ROC AUC: 0.9820647743274291\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=sqrt,bootstrap=True,oob_score=True,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9628796400449944 \n",
      "F1 Score: 0.8272251308900523 \n",
      "Precision: 0.8977272727272727 \n",
      "Recall: 0.7669902912621359 \n",
      "ROC AUC: 0.9834358556288446\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=sqrt,bootstrap=False,oob_score=False,class_weight=None) evaluated. \n",
      "Accuracy: 0.9662542182227222 \n",
      "F1 Score: 0.8421052631578947 \n",
      "Precision: 0.9195402298850575 \n",
      "Recall: 0.7766990291262136 \n",
      "ROC AUC: 0.9849922181872082\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=sqrt,bootstrap=False,oob_score=False,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9651293588301463 \n",
      "F1 Score: 0.8393782383419689 \n",
      "Precision: 0.9 \n",
      "Recall: 0.7864077669902912 \n",
      "ROC AUC: 0.9801193211294745\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=sqrt,bootstrap=False,oob_score=False,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9651293588301463 \n",
      "F1 Score: 0.8393782383419689 \n",
      "Precision: 0.9 \n",
      "Recall: 0.7864077669902912 \n",
      "ROC AUC: 0.9801193211294745\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=log2,bootstrap=True,oob_score=False,class_weight=None) evaluated. \n",
      "Accuracy: 0.9628796400449944 \n",
      "F1 Score: 0.8235294117647058 \n",
      "Precision: 0.9166666666666666 \n",
      "Recall: 0.7475728155339806 \n",
      "ROC AUC: 0.9819906618246498\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=log2,bootstrap=True,oob_score=False,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9628796400449944 \n",
      "F1 Score: 0.8307692307692308 \n",
      "Precision: 0.8804347826086957 \n",
      "Recall: 0.7864077669902912 \n",
      "ROC AUC: 0.9819536055732603\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=log2,bootstrap=True,oob_score=False,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9617547806524185 \n",
      "F1 Score: 0.8247422680412371 \n",
      "Precision: 0.8791208791208791 \n",
      "Recall: 0.7766990291262136 \n",
      "ROC AUC: 0.982225351416784\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=log2,bootstrap=True,oob_score=True,class_weight=None) evaluated. \n",
      "Accuracy: 0.9628796400449944 \n",
      "F1 Score: 0.8235294117647058 \n",
      "Precision: 0.9166666666666666 \n",
      "Recall: 0.7475728155339806 \n",
      "ROC AUC: 0.9819906618246498\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=log2,bootstrap=True,oob_score=True,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9628796400449944 \n",
      "F1 Score: 0.8307692307692308 \n",
      "Precision: 0.8804347826086957 \n",
      "Recall: 0.7864077669902912 \n",
      "ROC AUC: 0.9819536055732603\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=log2,bootstrap=True,oob_score=True,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9617547806524185 \n",
      "F1 Score: 0.8247422680412371 \n",
      "Precision: 0.8791208791208791 \n",
      "Recall: 0.7766990291262136 \n",
      "ROC AUC: 0.982225351416784\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=log2,bootstrap=False,oob_score=False,class_weight=None) evaluated. \n",
      "Accuracy: 0.9617547806524185 \n",
      "F1 Score: 0.8191489361702128 \n",
      "Precision: 0.9058823529411765 \n",
      "Recall: 0.7475728155339806 \n",
      "ROC AUC: 0.9835099681316237\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=log2,bootstrap=False,oob_score=False,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9640044994375703 \n",
      "F1 Score: 0.8350515463917526 \n",
      "Precision: 0.8901098901098901 \n",
      "Recall: 0.7864077669902912 \n",
      "ROC AUC: 0.982571209763087\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=log2,bootstrap=False,oob_score=False,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9640044994375703 \n",
      "F1 Score: 0.8350515463917526 \n",
      "Precision: 0.8901098901098901 \n",
      "Recall: 0.7864077669902912 \n",
      "ROC AUC: 0.982571209763087\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=None,bootstrap=True,oob_score=False,class_weight=None) evaluated. \n",
      "Accuracy: 0.9628796400449944 \n",
      "F1 Score: 0.8253968253968254 \n",
      "Precision: 0.9069767441860465 \n",
      "Recall: 0.7572815533980582 \n",
      "ROC AUC: 0.9824044566318337\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=None,bootstrap=True,oob_score=False,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9617547806524185 \n",
      "F1 Score: 0.8247422680412371 \n",
      "Precision: 0.8791208791208791 \n",
      "Recall: 0.7766990291262136 \n",
      "ROC AUC: 0.9814780503470935\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=None,bootstrap=True,oob_score=False,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9640044994375703 \n",
      "F1 Score: 0.8333333333333334 \n",
      "Precision: 0.898876404494382 \n",
      "Recall: 0.7766990291262136 \n",
      "ROC AUC: 0.9786494231576865\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=None,bootstrap=True,oob_score=True,class_weight=None) evaluated. \n",
      "Accuracy: 0.9628796400449944 \n",
      "F1 Score: 0.8253968253968254 \n",
      "Precision: 0.9069767441860465 \n",
      "Recall: 0.7572815533980582 \n",
      "ROC AUC: 0.9824044566318337\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=None,bootstrap=True,oob_score=True,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9617547806524185 \n",
      "F1 Score: 0.8247422680412371 \n",
      "Precision: 0.8791208791208791 \n",
      "Recall: 0.7766990291262136 \n",
      "ROC AUC: 0.9814780503470935\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=None,bootstrap=True,oob_score=True,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9640044994375703 \n",
      "F1 Score: 0.8333333333333334 \n",
      "Precision: 0.898876404494382 \n",
      "Recall: 0.7766990291262136 \n",
      "ROC AUC: 0.9786494231576865\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=None,bootstrap=False,oob_score=False,class_weight=None) evaluated. \n",
      "Accuracy: 0.9403824521934758 \n",
      "F1 Score: 0.7282051282051282 \n",
      "Precision: 0.7717391304347826 \n",
      "Recall: 0.6893203883495146 \n",
      "ROC AUC: 0.8435546826749674\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=None,bootstrap=False,oob_score=False,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9448818897637795 \n",
      "F1 Score: 0.772093023255814 \n",
      "Precision: 0.7410714285714286 \n",
      "Recall: 0.8058252427184466 \n",
      "ROC AUC: 0.9040119568171152\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=2,max_features=None,bootstrap=False,oob_score=False,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9448818897637795 \n",
      "F1 Score: 0.772093023255814 \n",
      "Precision: 0.7410714285714286 \n",
      "Recall: 0.8058252427184466 \n",
      "ROC AUC: 0.9040119568171152\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=sqrt,bootstrap=True,oob_score=False,class_weight=None) evaluated. \n",
      "Accuracy: 0.9606299212598425 \n",
      "F1 Score: 0.8108108108108109 \n",
      "Precision: 0.9146341463414634 \n",
      "Recall: 0.7281553398058253 \n",
      "ROC AUC: 0.9835223202154204\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=sqrt,bootstrap=True,oob_score=False,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9628796400449944 \n",
      "F1 Score: 0.8341708542713567 \n",
      "Precision: 0.8645833333333334 \n",
      "Recall: 0.8058252427184466 \n",
      "ROC AUC: 0.9823859285061389\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=sqrt,bootstrap=True,oob_score=False,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9640044994375703 \n",
      "F1 Score: 0.8383838383838383 \n",
      "Precision: 0.8736842105263158 \n",
      "Recall: 0.8058252427184466 \n",
      "ROC AUC: 0.984090516070061\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=sqrt,bootstrap=True,oob_score=True,class_weight=None) evaluated. \n",
      "Accuracy: 0.9606299212598425 \n",
      "F1 Score: 0.8108108108108109 \n",
      "Precision: 0.9146341463414634 \n",
      "Recall: 0.7281553398058253 \n",
      "ROC AUC: 0.9835223202154204\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=sqrt,bootstrap=True,oob_score=True,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9628796400449944 \n",
      "F1 Score: 0.8341708542713567 \n",
      "Precision: 0.8645833333333334 \n",
      "Recall: 0.8058252427184466 \n",
      "ROC AUC: 0.9823859285061389\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=sqrt,bootstrap=True,oob_score=True,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9640044994375703 \n",
      "F1 Score: 0.8383838383838383 \n",
      "Precision: 0.8736842105263158 \n",
      "Recall: 0.8058252427184466 \n",
      "ROC AUC: 0.984090516070061\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=sqrt,bootstrap=False,oob_score=False,class_weight=None) evaluated. \n",
      "Accuracy: 0.9640044994375703 \n",
      "F1 Score: 0.8297872340425532 \n",
      "Precision: 0.9176470588235294 \n",
      "Recall: 0.7572815533980582 \n",
      "ROC AUC: 0.9835779045925048\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=sqrt,bootstrap=False,oob_score=False,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9651293588301463 \n",
      "F1 Score: 0.8442211055276382 \n",
      "Precision: 0.875 \n",
      "Recall: 0.8155339805825242 \n",
      "ROC AUC: 0.9826576743496628\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=sqrt,bootstrap=False,oob_score=False,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9651293588301463 \n",
      "F1 Score: 0.8442211055276382 \n",
      "Precision: 0.875 \n",
      "Recall: 0.8155339805825242 \n",
      "ROC AUC: 0.9826576743496628\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=log2,bootstrap=True,oob_score=False,class_weight=None) evaluated. \n",
      "Accuracy: 0.9606299212598425 \n",
      "F1 Score: 0.8108108108108109 \n",
      "Precision: 0.9146341463414634 \n",
      "Recall: 0.7281553398058253 \n",
      "ROC AUC: 0.9822377035005805\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=log2,bootstrap=True,oob_score=False,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9617547806524185 \n",
      "F1 Score: 0.8316831683168316 \n",
      "Precision: 0.8484848484848485 \n",
      "Recall: 0.8155339805825242 \n",
      "ROC AUC: 0.9827194347686454\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=log2,bootstrap=True,oob_score=False,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9628796400449944 \n",
      "F1 Score: 0.8341708542713567 \n",
      "Precision: 0.8645833333333334 \n",
      "Recall: 0.8058252427184466 \n",
      "ROC AUC: 0.9836458410533857\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=log2,bootstrap=True,oob_score=True,class_weight=None) evaluated. \n",
      "Accuracy: 0.9606299212598425 \n",
      "F1 Score: 0.8108108108108109 \n",
      "Precision: 0.9146341463414634 \n",
      "Recall: 0.7281553398058253 \n",
      "ROC AUC: 0.9822377035005805\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=log2,bootstrap=True,oob_score=True,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9617547806524185 \n",
      "F1 Score: 0.8316831683168316 \n",
      "Precision: 0.8484848484848485 \n",
      "Recall: 0.8155339805825242 \n",
      "ROC AUC: 0.9827194347686454\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=log2,bootstrap=True,oob_score=True,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9628796400449944 \n",
      "F1 Score: 0.8341708542713567 \n",
      "Precision: 0.8645833333333334 \n",
      "Recall: 0.8058252427184466 \n",
      "ROC AUC: 0.9836458410533857\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=log2,bootstrap=False,oob_score=False,class_weight=None) evaluated. \n",
      "Accuracy: 0.9640044994375703 \n",
      "F1 Score: 0.8297872340425532 \n",
      "Precision: 0.9176470588235294 \n",
      "Recall: 0.7572815533980582 \n",
      "ROC AUC: 0.9795387731910372\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=log2,bootstrap=False,oob_score=False,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9606299212598425 \n",
      "F1 Score: 0.8258706467661692 \n",
      "Precision: 0.8469387755102041 \n",
      "Recall: 0.8058252427184466 \n",
      "ROC AUC: 0.9828058993552212\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=log2,bootstrap=False,oob_score=False,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9606299212598425 \n",
      "F1 Score: 0.8258706467661692 \n",
      "Precision: 0.8469387755102041 \n",
      "Recall: 0.8058252427184466 \n",
      "ROC AUC: 0.9828058993552212\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=None,bootstrap=True,oob_score=False,class_weight=None) evaluated. \n",
      "Accuracy: 0.9628796400449944 \n",
      "F1 Score: 0.8253968253968254 \n",
      "Precision: 0.9069767441860465 \n",
      "Recall: 0.7572815533980582 \n",
      "ROC AUC: 0.9832814545813879\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=None,bootstrap=True,oob_score=False,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9583802024746907 \n",
      "F1 Score: 0.8140703517587939 \n",
      "Precision: 0.84375 \n",
      "Recall: 0.7864077669902912 \n",
      "ROC AUC: 0.9818177326514984\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=None,bootstrap=True,oob_score=False,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9595050618672666 \n",
      "F1 Score: 0.8181818181818182 \n",
      "Precision: 0.8526315789473684 \n",
      "Recall: 0.7864077669902912 \n",
      "ROC AUC: 0.9787914721213469\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=None,bootstrap=True,oob_score=True,class_weight=None) evaluated. \n",
      "Accuracy: 0.9628796400449944 \n",
      "F1 Score: 0.8253968253968254 \n",
      "Precision: 0.9069767441860465 \n",
      "Recall: 0.7572815533980582 \n",
      "ROC AUC: 0.9832814545813879\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=None,bootstrap=True,oob_score=True,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9583802024746907 \n",
      "F1 Score: 0.8140703517587939 \n",
      "Precision: 0.84375 \n",
      "Recall: 0.7864077669902912 \n",
      "ROC AUC: 0.9818177326514984\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=None,bootstrap=True,oob_score=True,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9595050618672666 \n",
      "F1 Score: 0.8181818181818182 \n",
      "Precision: 0.8526315789473684 \n",
      "Recall: 0.7864077669902912 \n",
      "ROC AUC: 0.9787914721213469\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=None,bootstrap=False,oob_score=False,class_weight=None) evaluated. \n",
      "Accuracy: 0.9471316085489314 \n",
      "F1 Score: 0.7539267015706806 \n",
      "Precision: 0.8181818181818182 \n",
      "Recall: 0.6990291262135923 \n",
      "ROC AUC: 0.8691852565527804\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=None,bootstrap=False,oob_score=False,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9426321709786277 \n",
      "F1 Score: 0.7671232876712328 \n",
      "Precision: 0.7241379310344828 \n",
      "Recall: 0.8155339805825242 \n",
      "ROC AUC: 0.9055250870821907\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=None,min_samples_split=10,min_samples_leaf=4,max_features=None,bootstrap=False,oob_score=False,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9426321709786277 \n",
      "F1 Score: 0.7671232876712328 \n",
      "Precision: 0.7241379310344828 \n",
      "Recall: 0.8155339805825242 \n",
      "ROC AUC: 0.9055250870821907\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=5,min_samples_split=2,min_samples_leaf=1,max_features=sqrt,bootstrap=True,oob_score=False,class_weight=None) evaluated. \n",
      "Accuracy: 0.9595050618672666 \n",
      "F1 Score: 0.8064516129032258 \n",
      "Precision: 0.9036144578313253 \n",
      "Recall: 0.7281553398058253 \n",
      "ROC AUC: 0.9805331159366586\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=5,min_samples_split=2,min_samples_leaf=1,max_features=sqrt,bootstrap=True,oob_score=False,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9471316085489314 \n",
      "F1 Score: 0.7929515418502202 \n",
      "Precision: 0.7258064516129032 \n",
      "Recall: 0.8737864077669902 \n",
      "ROC AUC: 0.9820894784950222\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=5,min_samples_split=2,min_samples_leaf=1,max_features=sqrt,bootstrap=True,oob_score=False,class_weight=balanced_subsample) evaluated. \n",
      "Accuracy: 0.9471316085489314 \n",
      "F1 Score: 0.7929515418502202 \n",
      "Precision: 0.7258064516129032 \n",
      "Recall: 0.8737864077669902 \n",
      "ROC AUC: 0.981397761802416\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=5,min_samples_split=2,min_samples_leaf=1,max_features=sqrt,bootstrap=True,oob_score=True,class_weight=None) evaluated. \n",
      "Accuracy: 0.9595050618672666 \n",
      "F1 Score: 0.8064516129032258 \n",
      "Precision: 0.9036144578313253 \n",
      "Recall: 0.7281553398058253 \n",
      "ROC AUC: 0.9805331159366586\n",
      "Model RF(n_estimators=300,criterion=entropy,max_depth=5,min_samples_split=2,min_samples_leaf=1,max_features=sqrt,bootstrap=True,oob_score=True,class_weight=balanced) evaluated. \n",
      "Accuracy: 0.9471316085489314 \n",
      "F1 Score: 0.7929515418502202 \n",
      "Precision: 0.7258064516129032 \n",
      "Recall: 0.8737864077669902 \n",
      "ROC AUC: 0.9820894784950222\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[70]\u001B[39m\u001B[32m, line 58\u001B[39m\n\u001B[32m     44\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     45\u001B[39m     model = RandomForestClassifier(\n\u001B[32m     46\u001B[39m         n_estimators=n_est,\n\u001B[32m     47\u001B[39m         criterion=crit,\n\u001B[32m   (...)\u001B[39m\u001B[32m     56\u001B[39m         random_state=\u001B[32m3003\u001B[39m\n\u001B[32m     57\u001B[39m     )\n\u001B[32m---> \u001B[39m\u001B[32m58\u001B[39m     \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_tr_use\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_tr_use\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     59\u001B[39m     y_pred = model.predict(X_te_use)\n\u001B[32m     60\u001B[39m     y_proba = model.predict_proba(X_te_use)[:, \u001B[32m1\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/lib/python3.13/site-packages/sklearn/base.py:1365\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1358\u001B[39m     estimator._validate_params()\n\u001B[32m   1360\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1361\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1362\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1363\u001B[39m     )\n\u001B[32m   1364\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1365\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:533\u001B[39m, in \u001B[36mBaseForest.fit\u001B[39m\u001B[34m(self, X, y, sample_weight)\u001B[39m\n\u001B[32m    529\u001B[39m         \u001B[38;5;28mself\u001B[39m._set_oob_score_and_attributes(\n\u001B[32m    530\u001B[39m             X, y, scoring_function=\u001B[38;5;28mself\u001B[39m.oob_score\n\u001B[32m    531\u001B[39m         )\n\u001B[32m    532\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m533\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_set_oob_score_and_attributes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    535\u001B[39m \u001B[38;5;66;03m# Decapsulate classes_ attributes\u001B[39;00m\n\u001B[32m    536\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mclasses_\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.n_outputs_ == \u001B[32m1\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:817\u001B[39m, in \u001B[36mForestClassifier._set_oob_score_and_attributes\u001B[39m\u001B[34m(self, X, y, scoring_function)\u001B[39m\n\u001B[32m    805\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_set_oob_score_and_attributes\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y, scoring_function=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m    806\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Compute and set the OOB score and attributes.\u001B[39;00m\n\u001B[32m    807\u001B[39m \n\u001B[32m    808\u001B[39m \u001B[33;03m    Parameters\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    815\u001B[39m \u001B[33;03m        Scoring function for OOB score. Defaults to `accuracy_score`.\u001B[39;00m\n\u001B[32m    816\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m817\u001B[39m     \u001B[38;5;28mself\u001B[39m.oob_decision_function_ = \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_compute_oob_predictions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    818\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.oob_decision_function_.shape[-\u001B[32m1\u001B[39m] == \u001B[32m1\u001B[39m:\n\u001B[32m    819\u001B[39m         \u001B[38;5;66;03m# drop the n_outputs axis if there is a single output\u001B[39;00m\n\u001B[32m    820\u001B[39m         \u001B[38;5;28mself\u001B[39m.oob_decision_function_ = \u001B[38;5;28mself\u001B[39m.oob_decision_function_.squeeze(axis=-\u001B[32m1\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:605\u001B[39m, in \u001B[36mBaseForest._compute_oob_predictions\u001B[39m\u001B[34m(self, X, y)\u001B[39m\n\u001B[32m    598\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m estimator \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.estimators_:\n\u001B[32m    599\u001B[39m     unsampled_indices = _generate_unsampled_indices(\n\u001B[32m    600\u001B[39m         estimator.random_state,\n\u001B[32m    601\u001B[39m         n_samples,\n\u001B[32m    602\u001B[39m         n_samples_bootstrap,\n\u001B[32m    603\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m605\u001B[39m     y_pred = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_oob_predictions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m[\u001B[49m\u001B[43munsampled_indices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    606\u001B[39m     oob_pred[unsampled_indices, ...] += y_pred\n\u001B[32m    607\u001B[39m     n_oob_pred[unsampled_indices, :] += \u001B[32m1\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:777\u001B[39m, in \u001B[36mForestClassifier._get_oob_predictions\u001B[39m\u001B[34m(tree, X)\u001B[39m\n\u001B[32m    747\u001B[39m \u001B[38;5;129m@abstractmethod\u001B[39m\n\u001B[32m    748\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\n\u001B[32m    749\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    761\u001B[39m     max_samples=\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    762\u001B[39m ):\n\u001B[32m    763\u001B[39m     \u001B[38;5;28msuper\u001B[39m().\u001B[34m__init__\u001B[39m(\n\u001B[32m    764\u001B[39m         estimator=estimator,\n\u001B[32m    765\u001B[39m         n_estimators=n_estimators,\n\u001B[32m   (...)\u001B[39m\u001B[32m    774\u001B[39m         max_samples=max_samples,\n\u001B[32m    775\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m777\u001B[39m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[32m    778\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_get_oob_predictions\u001B[39m(tree, X):\n\u001B[32m    779\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Compute the OOB predictions for an individual tree.\u001B[39;00m\n\u001B[32m    780\u001B[39m \n\u001B[32m    781\u001B[39m \u001B[33;03m    Parameters\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    791\u001B[39m \u001B[33;03m        The OOB associated predictions.\u001B[39;00m\n\u001B[32m    792\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m    793\u001B[39m     y_pred = tree.predict_proba(X, check_input=\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, roc_curve, \\\n",
    "    confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_tr = x_train_added if 'x_train_added' in globals() else x_train\n",
    "X_te = x_test_added if 'x_test_added' in globals() else x_test\n",
    "\n",
    "if isinstance(X_tr, np.ndarray):\n",
    "    X_tr_use = X_tr\n",
    "    X_te_use = X_te\n",
    "else:\n",
    "    X_tr_use = X_tr.values\n",
    "    X_te_use = X_te.values\n",
    "\n",
    "y_tr_use = y_train.values if isinstance(y_train, pd.Series) else y_train\n",
    "y_te_use = y_test.values if isinstance(y_test, pd.Series) else y_test\n",
    "\n",
    "n_neighbors_grid = list(range(1, 51))\n",
    "weights_grid = ['uniform', 'distance']\n",
    "metric_grid = ['minkowski', 'euclidean', 'manhattan', 'chebyshev']\n",
    "p_by_metric = {'minkowski': [1, 2, 3], 'euclidean': [2], 'manhattan': [1], 'chebyshev': [None]}\n",
    "leaf_size_grid = [15, 30, 45, 60]\n",
    "algorithm_grid = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "\n",
    "for n in n_neighbors_grid:\n",
    "    for w in weights_grid:\n",
    "        for alg in algorithm_grid:\n",
    "            for leaf in leaf_size_grid:\n",
    "                for m in metric_grid:\n",
    "                    for p in p_by_metric[m]:\n",
    "                        try:\n",
    "                            kwargs = dict(\n",
    "                                n_neighbors=n,\n",
    "                                weights=w,\n",
    "                                algorithm=alg,\n",
    "                                leaf_size=leaf,\n",
    "                                metric=m,\n",
    "                                n_jobs=-1\n",
    "                            )\n",
    "                            if p is not None and m == 'minkowski':\n",
    "                                kwargs['p'] = p\n",
    "                            elif m != 'minkowski' and 'p' in kwargs:\n",
    "                                kwargs.pop('p', None)\n",
    "                            elif m == 'minkowski' and p is None:\n",
    "                                kwargs['p'] = 2\n",
    "\n",
    "                            model = KNeighborsClassifier(**kwargs)\n",
    "                            model.fit(X_tr_use, y_tr_use)\n",
    "                            y_pred = model.predict(X_te_use)\n",
    "                            if hasattr(model, \"predict_proba\"):\n",
    "                                y_proba = model.predict_proba(X_te_use)[:, 1]\n",
    "                            else:\n",
    "                                # Fallback using distance to neighbors if proba not available\n",
    "                                # For KNN classifiers with weights this should exist; safeguard:\n",
    "                                y_proba = y_pred.astype(float)\n",
    "\n",
    "                            acc = accuracy_score(y_te_use, y_pred)\n",
    "                            f1 = f1_score(y_te_use, y_pred)\n",
    "                            prec = precision_score(y_te_use, y_pred)\n",
    "                            rec = recall_score(y_te_use, y_pred)\n",
    "\n",
    "                            try:\n",
    "                                auc = roc_auc_score(y_te_use, y_proba)\n",
    "                                roc_cur = roc_curve(y_te_use, y_proba)\n",
    "                            except Exception:\n",
    "                                # In rare cases when y_proba is degenerate\n",
    "                                auc = float('nan')\n",
    "                                roc_cur = (np.array([0.0, 1.0]), np.array([0.0, 1.0]), np.array([0.5]))\n",
    "\n",
    "                            cm = confusion_matrix(y_true=y_te_use, y_pred=y_pred, normalize='true')\n",
    "                            name = f\"KNN(n_neighbors={n},weights={w},algorithm={alg},leaf_size={leaf},metric={m}\" + (\n",
    "                                f\",p={p}\" if m == 'minkowski' else \"\") + \")\"\n",
    "                            hyperParameterResults(name, acc, f1, prec, rec, auc, roc_cur, cm)\n",
    "                        except Exception:\n",
    "                            continue\n"
   ],
   "id": "54c9159e9bf71996",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, roc_curve, \\\n",
    "    confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_tr = x_train_added if 'x_train_added' in globals() else x_train\n",
    "X_te = x_test_added if 'x_test_added' in globals() else x_test\n",
    "\n",
    "if isinstance(X_tr, np.ndarray):\n",
    "    X_tr_use = X_tr\n",
    "    X_te_use = X_te\n",
    "else:\n",
    "    X_tr_use = X_tr.values\n",
    "    X_te_use = X_te.values\n",
    "\n",
    "y_tr_use = y_train.values if isinstance(y_train, pd.Series) else y_train\n",
    "y_te_use = y_test.values if isinstance(y_test, pd.Series) else y_test\n",
    "\n",
    "n_estimators_grid = [50, 100, 200, 300, 500, 800, 1000, 2000, 4000, 5000]\n",
    "learning_rate_grid = [0.01, 0.05, 0.1, 0.2, 0.5, 1.0]\n",
    "algorithm_grid = ['SAMME', 'SAMME.R']\n",
    "\n",
    "dt_max_depth_grid = [1, 2, 3, 4, 5]\n",
    "dt_min_samples_split_grid = [2, 5, 10]\n",
    "dt_min_samples_leaf_grid = [1, 2, 4]\n",
    "\n",
    "for n_est in n_estimators_grid:\n",
    "    for lr in learning_rate_grid:\n",
    "        for algo in algorithm_grid:\n",
    "            for md in dt_max_depth_grid:\n",
    "                for mss in dt_min_samples_split_grid:\n",
    "                    for msl in dt_min_samples_leaf_grid:\n",
    "                        try:\n",
    "                            base = DecisionTreeClassifier(\n",
    "                                max_depth=md,\n",
    "                                min_samples_split=mss,\n",
    "                                min_samples_leaf=msl,\n",
    "                                random_state=3003\n",
    "                            )\n",
    "                            model = AdaBoostClassifier(\n",
    "                                estimator=base,\n",
    "                                n_estimators=n_est,\n",
    "                                learning_rate=lr,\n",
    "                                algorithm=algo,\n",
    "                                random_state=3003\n",
    "                            )\n",
    "                            model.fit(X_tr_use, y_tr_use)\n",
    "                            y_pred = model.predict(X_te_use)\n",
    "                            if hasattr(model, \"predict_proba\"):\n",
    "                                y_proba = model.predict_proba(X_te_use)[:, 1]\n",
    "                            else:\n",
    "                                if hasattr(model, \"decision_function\"):\n",
    "                                    scores = model.decision_function(X_te_use)\n",
    "                                    y_proba = (scores - scores.min()) / (scores.max() - scores.min() + 1e-12)\n",
    "                                else:\n",
    "                                    y_proba = y_pred.astype(float)\n",
    "\n",
    "                            acc = accuracy_score(y_te_use, y_pred)\n",
    "                            f1 = f1_score(y_te_use, y_pred)\n",
    "                            prec = precision_score(y_te_use, y_pred)\n",
    "                            rec = recall_score(y_te_use, y_pred)\n",
    "\n",
    "                            try:\n",
    "                                auc = roc_auc_score(y_te_use, y_proba)\n",
    "                                roc_cur = roc_curve(y_te_use, y_proba)\n",
    "                            except Exception:\n",
    "                                auc = float('nan')\n",
    "                                roc_cur = (np.array([0.0, 1.0]), np.array([0.0, 1.0]), np.array([0.5]))\n",
    "\n",
    "                            cm = confusion_matrix(y_true=y_te_use, y_pred=y_pred, normalize='true')\n",
    "                            name = f\"AdaBoost(n_estimators={n_est},lr={lr},alg={algo},DT(max_depth={md},min_split={mss},min_leaf={msl}))\"\n",
    "                            hyperParameterResults(name, acc, f1, prec, rec, auc, roc_cur, cm)\n",
    "                        except Exception:\n",
    "                            continue\n"
   ],
   "id": "d909952b361e4256",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Best Voting Classifier Search",
   "id": "fd98267233aa3880"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "\n",
    "# Define the pool of base classifiers with various hyperparameters\n",
    "classifiers_pool = [\n",
    "    ('LR_balanced', LogisticRegression(multi_class='auto', max_iter=1000, class_weight='balanced', random_state=3003)),\n",
    "    ('LR_default', LogisticRegression(multi_class='auto', max_iter=1000, random_state=3003)),\n",
    "    ('RF_100', RandomForestClassifier(n_estimators=100, random_state=3003)),\n",
    "    ('RF_200', RandomForestClassifier(n_estimators=200, random_state=3003)),\n",
    "    ('RF_300', RandomForestClassifier(n_estimators=200, random_state=3003)),\n",
    "    ('KNN_5', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('KNN_7', KNeighborsClassifier(n_neighbors=7)),\n",
    "    ('GBC_100', GradientBoostingClassifier(n_estimators=100, random_state=3003)),\n",
    "    ('GBC_200', GradientBoostingClassifier(n_estimators=200, random_state=3003)),\n",
    "    ('Ada_50', AdaBoostClassifier(n_estimators=50, random_state=3003)),\n",
    "    ('Ada_100', AdaBoostClassifier(n_estimators=100, random_state=3003))\n",
    "]\n",
    "\n",
    "best_f1_found = -1\n",
    "best_voting_model = None\n",
    "best_ensemble_name = \"\"\n",
    "\n",
    "print(\"Searching for best Voting Classifier configuration (optimizing for F1 Score)...\")\n",
    "\n",
    "# Iterate through all possible combinations of length 2 to 4 (limiting to 4 to avoid too long runtime)\n",
    "for r in range(2, 5):\n",
    "    for ensemble in itertools.combinations(classifiers_pool, r):\n",
    "        # Create a name for this combination\n",
    "        names = [name for name, _ in ensemble]\n",
    "        ensemble_name = f\"BestVote ({'+'.join(names)})\"\n",
    "\n",
    "        # Create the voting classifier\n",
    "        # Using soft voting as these models support probability estimates\n",
    "        voter = VotingClassifier(estimators=list(ensemble), voting='soft', n_jobs=-1)\n",
    "\n",
    "        # Train\n",
    "        voter.fit(x_train_added, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = voter.predict(x_test_added)\n",
    "        y_pred_proba = voter.predict_proba(x_test_added)[:, 1]\n",
    "\n",
    "        # Evaluate\n",
    "        current_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        roc_cur = roc_curve(y_test, y_pred_proba)\n",
    "        cm = confusion_matrix(y_true=y_test, y_pred=y_pred, normalize='true')\n",
    "        modelResults(ensemble, accuracy, current_f1, precision, recall, roc_auc, roc_cur, cm)\n",
    "\n",
    "\n",
    "\n",
    "        # print(f\"Tested {ensemble_name}: F1 Score = {current_f1:.4f}\")\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        roc_cur = roc_curve(y_test, y_pred_proba)\n",
    "        cm = confusion_matrix(y_true=y_test, y_pred=y_pred, normalize='true')\n",
    "\n",
    "        modelResults(ensemble_name, accuracy, current_f1, precision, recall, roc_auc, roc_cur, cm)\n",
    "\n",
    "        if current_f1 > best_f1_found:\n",
    "            best_f1_found = current_f1\n",
    "            best_voting_model = voter\n",
    "            best_ensemble_name = ensemble_name\n",
    "\n",
    "print(f\"\\nWinner configuration: {best_ensemble_name} with F1 Score: {best_f1_found:.4f}\")\n",
    "\n",
    "# Log the best result to the global resultsTable\n",
    "if best_voting_model:\n",
    "    y_pred = best_voting_model.predict(x_test)\n",
    "    y_pred_proba = best_voting_model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    roc_cur = roc_curve(y_test, y_pred_proba)\n",
    "    cm = confusion_matrix(y_true=y_test, y_pred=y_pred, normalize='true')\n",
    "\n",
    "    # Plot matrix for the winner\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_voting_model.classes_)\n",
    "    disp.plot()\n",
    "    plt.title(f\"Best Found Ensemble: {best_ensemble_name}\")\n",
    "    plt.show()"
   ],
   "id": "33ccb24c52904e91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T23:35:54.763085Z",
     "start_time": "2025-11-26T23:35:54.759289Z"
    }
   },
   "cell_type": "code",
   "source": "hyperParameterResultsTable.to_csv(\"data/hyperParameterResults.csv\", index=False, mode=\"a\")",
   "id": "e2ebf860dbc7127f",
   "outputs": [],
   "execution_count": 71
  },
  {
   "cell_type": "markdown",
   "id": "e2078b02730ef972",
   "metadata": {},
   "source": [
    "# Model evaluation\n",
    "## Quick conclusion"
   ]
  },
  {
   "cell_type": "code",
   "id": "a74e735f580bc275",
   "metadata": {},
   "source": [
    "original_size = resultsTable.shape[0]\n",
    "resultsTable = resultsTable.drop_duplicates(subset=['Model', 'Accuracy', 'F1 Score', 'Precision', 'Recall', 'ROC_AUC'])\n",
    "print(f\"Dropped {original_size - resultsTable.shape[0]} duplicate rows\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "22fb0d0456fb3e19",
   "metadata": {},
   "source": [
    "resultsTable"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c38fea59ebb09553",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T23:36:03.157262Z",
     "start_time": "2025-11-26T23:36:03.153986Z"
    }
   },
   "source": [
    "top_models = hyperParameterResultsTable.sort_values(by='F1 Score', ascending=False).head(5)\n",
    "\n",
    "print(\"Top 5 models based on F1 score:\")\n",
    "for i, (_, row) in enumerate(top_models.iterrows(), 1):\n",
    "    print(f\"{i}. {row['Model']} with an F1 score of {row['F1 Score']:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 models based on F1 score:\n",
      "1. LR(solver=lbfgs,penalty=l2,C=0.01,class_weight=None) with an F1 score of 0.7629\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "cell_type": "markdown",
   "id": "e8e285a0ca7eadd2",
   "metadata": {},
   "source": [
    "## Graphs of numerical metrics\n",
    "### Logarithmic scale"
   ]
  },
  {
   "cell_type": "code",
   "id": "fb7c2b82a89e3bf8",
   "metadata": {},
   "source": [
    "if True:\n",
    "    numeric_metrics = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'ROC_AUC']\n",
    "\n",
    "    model_labels = [str(model).split('(')[0] for model in resultsTable['Model']]\n",
    "\n",
    "    fig, axes = plt.subplots(len(numeric_metrics), 1, figsize=(10, len(numeric_metrics) * 8))\n",
    "\n",
    "    for i, col in enumerate(numeric_metrics):\n",
    "        bars = axes[i].bar(range(len(resultsTable)), resultsTable[col])\n",
    "        axes[i].set_xticks(range(len(resultsTable)))\n",
    "        axes[i].set_xticklabels(model_labels, rotation=45, ha='right')\n",
    "        axes[i].set_ylabel(col)\n",
    "        axes[i].set_title(f'{col} by Model')\n",
    "        axes[i].set_yscale('log')\n",
    "        axes[i].grid(axis='y', alpha=0.3)\n",
    "\n",
    "        for j, bar in enumerate(bars):\n",
    "            height = bar.get_height()\n",
    "            axes[i].text(bar.get_x() + bar.get_width() / 2., height,\n",
    "                         f'{resultsTable[col].iloc[j]:.3f}',\n",
    "                         ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1738534b97511a26",
   "metadata": {},
   "source": [
    "numeric_metrics = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'ROC_AUC']\n",
    "\n",
    "model_labels = [str(model).split('(')[0] for model in resultsTable['Model']]\n",
    "\n",
    "fig, axes = plt.subplots(len(numeric_metrics), 1, figsize=(10, len(numeric_metrics) * 8))\n",
    "\n",
    "for i, col in enumerate(numeric_metrics):\n",
    "    bars = axes[i].bar(range(len(resultsTable)), resultsTable[col])\n",
    "    axes[i].set_xticks(range(len(resultsTable)))\n",
    "    axes[i].set_xticklabels(model_labels, rotation=45, ha='right')\n",
    "    axes[i].set_ylabel(col)\n",
    "    axes[i].set_title(f'{col} by Model')\n",
    "    axes[i].set_ylim(top=1)\n",
    "    axes[i].grid(axis='y', alpha=0.3)\n",
    "\n",
    "    for j, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        axes[i].text(bar.get_x() + bar.get_width() / 2., height,\n",
    "                     f'{resultsTable[col].iloc[j]:.3f}',\n",
    "                     ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2f15fb5d2e241296",
   "metadata": {},
   "source": [
    "## ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "id": "fd4a03846706aed",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for idx, row in resultsTable.iterrows():\n",
    "    model_name = str(row['Model']).split('(')[0]\n",
    "    fpr, tpr, thresholds = row['ROC']\n",
    "    roc_auc = row['ROC_AUC']\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{model_name} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier (AUC = 0.500)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curves - Model Comparison', fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=12)\n",
    "plt.grid(alpha=1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data-Witches",
   "language": "python",
   "name": "data-witches"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
